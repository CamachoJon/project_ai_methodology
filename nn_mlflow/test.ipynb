{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of splitted_data (272635, 6)\n"
     ]
    }
   ],
   "source": [
    "def prepare_data():\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv('../Dataset/projects.csv')\n",
    "    df_original = df.copy()\n",
    "    # df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X = df.drop(columns=['state', 'name'])\n",
    "    y = df['state']\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=42, test_size=0.1, stratify=y_train_val)\n",
    "\n",
    "    # Return all of the variables in a list\n",
    "    return [X_train, y_train, X_val, y_val, X_test, y_test]\n",
    "\n",
    "splitted_data = prepare_data()\n",
    "print('Shape of splitted_data', splitted_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features:  (272635, 198)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def ohe_train_encode(X):\n",
    "  ohe = OneHotEncoder(sparse_output=False)\n",
    "  X_ohe = ohe.fit_transform(X)\n",
    "  std = StandardScaler()\n",
    "  X_ohe_scl = std.fit_transform(X_ohe)\n",
    "  return X_ohe_scl, ohe, std\n",
    "\n",
    "def ohe_not_train_encode(X, ohe=None, std=None):\n",
    "  X_ohe = ohe.transform(X)\n",
    "  X_ohe_scl = std.transform(X_ohe)\n",
    "  return X_ohe_scl\n",
    "\n",
    "def cyclical_encode(df, col, max_val):\n",
    "    df = df.copy()\n",
    "    df[col + '_sin'] = np.sin(2 * np.pi * df[col] / max_val)\n",
    "    df[col + '_cos'] = np.cos(2 * np.pi * df[col] / max_val)\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_label_encoder(y):\n",
    "  lbl_enc = LabelEncoder()\n",
    "  encoded_labels = lbl_enc.fit_transform(y)\n",
    "  return encoded_labels, lbl_enc\n",
    "\n",
    "def not_train_label_encoder(y, lbl_enc=None):\n",
    "  encoded_labels = lbl_enc.transform(y)\n",
    "  return encoded_labels\n",
    "\n",
    "def fprepare_data(data_variables):\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = data_variables\n",
    "    \n",
    "    y_train, lbl_enc = train_label_encoder(y_train)\n",
    "    y_val = not_train_label_encoder(y_val, lbl_enc=lbl_enc)\n",
    "    y_test = not_train_label_encoder(y_test, lbl_enc=lbl_enc)\n",
    "\n",
    "    X_train_to_ohe = X_train[['category','main_category', 'currency' ]].astype(str)\n",
    "\n",
    "    X_val_to_ohe = X_val[['category','main_category', 'currency' ]].astype(str)\n",
    "\n",
    "    X_test_to_ohe = X_test[['category','main_category', 'currency' ]].astype(str)\n",
    "\n",
    "    X_train['deadline'] = pd.to_datetime(X_train['deadline'])\n",
    "    X_train['year_deadline'] = X_train['deadline'].dt.year\n",
    "    X_train['month_deadline'] = X_train['deadline'].dt.month\n",
    "    X_train['day_deadline'] = X_train['deadline'].dt.day\n",
    "    X_train.drop('deadline', axis=1, inplace=True)\n",
    "\n",
    "    X_train['launched'] = pd.to_datetime(X_train['launched'])\n",
    "    X_train['year_launched'] = X_train['launched'].dt.year\n",
    "    X_train['month_launched'] = X_train['launched'].dt.month\n",
    "    X_train['day_launched'] = X_train['launched'].dt.day\n",
    "    X_train['hour_launched'] = X_train['launched'].dt.hour\n",
    "    X_train.drop('launched', axis=1, inplace=True)\n",
    "\n",
    "    X_val['deadline'] = pd.to_datetime(X_val['deadline'])\n",
    "    X_val['year_deadline'] = X_val['deadline'].dt.year\n",
    "    X_val['month_deadline'] = X_val['deadline'].dt.month\n",
    "    X_val['day_deadline'] = X_val['deadline'].dt.day\n",
    "    X_val.drop('deadline', axis=1, inplace=True)\n",
    "\n",
    "    X_val['launched'] = pd.to_datetime(X_val['launched'])\n",
    "    X_val['year_launched'] = X_val['launched'].dt.year\n",
    "    X_val['month_launched'] = X_val['launched'].dt.month\n",
    "    X_val['day_launched'] = X_val['launched'].dt.day\n",
    "    X_val['hour_launched'] = X_val['launched'].dt.hour\n",
    "    X_val.drop('launched', axis=1, inplace=True)\n",
    "\n",
    "    X_test['deadline'] = pd.to_datetime(X_test['deadline'])\n",
    "    X_test['year_deadline'] = X_test['deadline'].dt.year\n",
    "    X_test['month_deadline'] = X_test['deadline'].dt.month\n",
    "    X_test['day_deadline'] = X_test['deadline'].dt.day\n",
    "    X_test.drop('deadline', axis=1, inplace=True)\n",
    "\n",
    "    X_test['launched'] = pd.to_datetime(X_test['launched'])\n",
    "    X_test['year_launched'] = X_test['launched'].dt.year\n",
    "    X_test['month_launched'] = X_test['launched'].dt.month\n",
    "    X_test['day_launched'] = X_test['launched'].dt.day\n",
    "    X_test['hour_launched'] = X_test['launched'].dt.hour\n",
    "    X_test.drop('launched', axis=1, inplace=True)\n",
    "\n",
    "    X_train_to_cyclical = X_train[['month_deadline', 'day_deadline', 'month_launched', 'day_launched', 'hour_launched']]\n",
    "    X_train_to_cyclical.head()\n",
    "\n",
    "    X_val_to_cyclical = X_val[['month_deadline', 'day_deadline', 'month_launched', 'day_launched', 'hour_launched']]\n",
    "    X_val_to_cyclical.head()\n",
    "\n",
    "    X_test_to_cyclical = X_test[['month_deadline', 'day_deadline', 'month_launched', 'day_launched', 'hour_launched']]\n",
    "    X_test_to_cyclical.head()\n",
    "\n",
    "    X_train_ohe, ohe, std = ohe_train_encode(X_train_to_ohe)\n",
    "    X_val_ohe = ohe_not_train_encode(X_val_to_ohe, ohe=ohe, std=std)\n",
    "    X_test_ohe = ohe_not_train_encode(X_test_to_ohe, ohe=ohe, std=std)\n",
    "\n",
    "    X_train_month_deadline_encoded = cyclical_encode(X_train_to_cyclical[['month_deadline']], 'month_deadline', 12)\n",
    "    X_val_month_deadline_encoded = cyclical_encode(X_val_to_cyclical[['month_deadline']], 'month_deadline', 12)\n",
    "    X_test_month_deadline_encoded = cyclical_encode(X_test_to_cyclical[['month_deadline']], 'month_deadline', 12)\n",
    "\n",
    "    X_train_month_launched_encoded = cyclical_encode(X_train_to_cyclical[['month_launched']], 'month_launched', 12)\n",
    "    X_val_month_launched_encoded = cyclical_encode(X_val_to_cyclical[['month_launched']], 'month_launched', 12)\n",
    "    X_test_month_launched_encoded = cyclical_encode(X_test_to_cyclical[['month_launched']], 'month_launched', 12)\n",
    "\n",
    "    X_train_day_deadline_encoded = cyclical_encode(X_train_to_cyclical[['day_deadline']], 'day_deadline', 30)\n",
    "    X_val_day_deadline_encoded = cyclical_encode(X_val_to_cyclical[['day_deadline']], 'day_deadline', 30)\n",
    "    X_test_day_deadline_encoded = cyclical_encode(X_test_to_cyclical[['day_deadline']], 'day_deadline', 30)\n",
    "\n",
    "    X_train_day_launched_encoded = cyclical_encode(X_train_to_cyclical[['day_launched']], 'day_launched', 30)\n",
    "    X_val_day_launched_encoded = cyclical_encode(X_val_to_cyclical[['day_launched']], 'day_launched', 30)\n",
    "    X_test_day_launched_encoded = cyclical_encode(X_test_to_cyclical[['day_launched']], 'day_launched', 30)\n",
    "\n",
    "    X_train_hour_launched_encoded = cyclical_encode(X_train_to_cyclical[['hour_launched']], 'hour_launched', 24)\n",
    "    X_val_hour_launched_encoded = cyclical_encode(X_val_to_cyclical[['hour_launched']], 'hour_launched', 24)\n",
    "    X_test_hour_launched_encoded = cyclical_encode(X_test_to_cyclical[['hour_launched']], 'hour_launched', 24)\n",
    "    \n",
    "    X_train = np.concatenate((X_train_ohe, X_train_month_deadline_encoded,\n",
    "                              X_train_month_launched_encoded,\n",
    "                              X_train_day_deadline_encoded,\n",
    "                              X_train_day_launched_encoded,\n",
    "                              X_train_hour_launched_encoded\n",
    "                              ), axis=1)\n",
    "    \n",
    "    X_val = np.concatenate((X_val_ohe, X_val_month_deadline_encoded,\n",
    "                              X_val_month_launched_encoded,\n",
    "                              X_val_day_deadline_encoded,\n",
    "                              X_val_day_launched_encoded,\n",
    "                              X_val_hour_launched_encoded\n",
    "                              ), axis=1)\n",
    "    \n",
    "    X_test = np.concatenate((X_test_ohe, X_test_month_deadline_encoded,\n",
    "                              X_test_month_launched_encoded,\n",
    "                              X_test_day_deadline_encoded,\n",
    "                              X_test_day_launched_encoded,\n",
    "                              X_test_hour_launched_encoded\n",
    "                              ), axis=1)\n",
    "    \n",
    "    # check if X_train and y_train have the same number of rows, if not, raise an error\n",
    "    if X_train.shape[0] != y_train.shape[0]:\n",
    "        raise ValueError('X_train and y_train must have the same number of rows')\n",
    "    \n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "features = fprepare_data(splitted_data)\n",
    "#print shape\n",
    "print('Shape of features: ', features[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "def prediction(model, X_test, y_test):\n",
    "    y_pred = (model.predict(X_test) > 0.5) * 1\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # General metrics \n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    print('Precision: ', round(precision_score(y_test, y_pred.astype(int), average='weighted'), 3))\n",
    "    print('Recall: ', round(recall_score(y_test, y_pred.astype(int), average='weighted'), 3))\n",
    "    print('F1 score: ', round(f1_score(y_test, y_pred.astype(int), average='weighted'), 3))\n",
    "\n",
    "    # Save model\n",
    "    tf.saved_model.save(model, 'saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "def reset_seeds():\n",
    "    os.environ['PYTHONHASHSEED'] = str(2)\n",
    "    tf.random.set_seed(2)\n",
    "    np.random.seed(2)\n",
    "    random.seed(2)\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val):   \n",
    "    \n",
    "    def build_model(hp):\n",
    "        model = keras.Sequential([\n",
    "            keras.Input(shape=(X_train.shape[1],), name=\"input\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(hp.Int('units1', 16, 64, step=16), activation=keras.activations.selu, name=\"hidden_layer1\", kernel_initializer=keras.initializers.LecunNormal),\n",
    "            keras.layers.Dropout(rate=hp.Float('dropout2', 0, 0.5, step=0.1)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(hp.Int('units2', 8, 32, step=8), activation=keras.activations.selu, name=\"hidden_layer2\", kernel_initializer=keras.initializers.LecunNormal),\n",
    "            layers.Dense(1, activation=\"sigmoid\", name=\"output\")\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    tuner = RandomSearch(\n",
    "        build_model,\n",
    "        objective='val_accuracy',\n",
    "        max_trials=5,\n",
    "        executions_per_trial=1,\n",
    "        directory='tuner_dir',\n",
    "        project_name='my_model'\n",
    "    )\n",
    "    tuner.search(X_train, y_train, epochs=20, validation_data=(X_val, y_val))\n",
    "\n",
    "    # Retrieve best hyperparameters and fit the final model\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
    "    model = tuner.hypermodel.build(best_hyperparameters)\n",
    "    model.fit(X_train, y_train, epochs=50, validation_data=(X_val, y_val))\n",
    "\n",
    "    # model = keras.Sequential(\n",
    "    #     [\n",
    "    #         keras.Input(shape=(X_train.shape[1],), name=\"input\"),\n",
    "    #         layers.BatchNormalization(),\n",
    "    #         layers.Dense(8, activation=keras.activations.selu, name=\"hidden_layer2\", kernel_initializer=keras.initializers.LecunNormal, kernel_regularizer='l1_l2'),\n",
    "    #         layers.Dense(1, activation=\"sigmoid\", name=\"output\")\n",
    "    #     ]\n",
    "    # )\n",
    "\n",
    "    # model.compile(\n",
    "    #     optimizer=tf.keras.optimizers.Adam(learning_rate=keras.optimizers.schedules.ExponentialDecay(0.1, decay_steps=100, decay_rate=0.96, staircase=True)),\n",
    "    #     loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    #     metrics=['accuracy']\n",
    "    # )\n",
    "\n",
    "    # cb = tf.keras.callbacks.EarlyStopping(\n",
    "    #     patience=5,\n",
    "    #     restore_best_weights=True\n",
    "    # )\n",
    "\n",
    "    reset_seeds()\n",
    "\n",
    "    # fitted_model = model.fit(\n",
    "    #     x=X_train,\n",
    "    #     y=y_train,\n",
    "    #     batch_size=32,\n",
    "    #     epochs=50,\n",
    "    #     validation_data=(X_val, y_val),\n",
    "    #     callbacks=cb, # use early stopping\n",
    "    # )\n",
    "    return model\n",
    "    # return fitted_model, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tuner_dir\\my_model\\tuner0.json\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "64                |64                |units1\n",
      "0.4               |0.4               |dropout2\n",
      "8                 |8                 |units2\n",
      "0.0061613         |0.0061613         |learning_rate\n",
      "\n",
      "Epoch 1/20\n",
      "8520/8520 [==============================] - 22s 2ms/step - loss: -14739747.0000 - accuracy: 0.0556 - val_loss: -53295848.0000 - val_accuracy: 0.0570\n",
      "Epoch 2/20\n",
      "8520/8520 [==============================] - 20s 2ms/step - loss: -148728160.0000 - accuracy: 0.0560 - val_loss: -307280928.0000 - val_accuracy: 0.0572\n",
      "Epoch 3/20\n",
      "8520/8520 [==============================] - 20s 2ms/step - loss: -521979744.0000 - accuracy: 0.0558 - val_loss: -909344960.0000 - val_accuracy: 0.0572\n",
      "Epoch 4/20\n",
      "8520/8520 [==============================] - 21s 2ms/step - loss: -1241155840.0000 - accuracy: 0.0559 - val_loss: -1876338176.0000 - val_accuracy: 0.0572\n",
      "Epoch 5/20\n",
      "8520/8520 [==============================] - 21s 2ms/step - loss: -2411798784.0000 - accuracy: 0.0559 - val_loss: -3319110912.0000 - val_accuracy: 0.0571\n",
      "Epoch 6/20\n",
      "8520/8520 [==============================] - 21s 2ms/step - loss: -4140932096.0000 - accuracy: 0.0558 - val_loss: -5477586432.0000 - val_accuracy: 0.0567\n",
      "Epoch 7/20\n",
      "8520/8520 [==============================] - 21s 2ms/step - loss: -6522666496.0000 - accuracy: 0.0559 - val_loss: -8662094848.0000 - val_accuracy: 0.0571\n",
      "Epoch 8/20\n",
      "8520/8520 [==============================] - 21s 2ms/step - loss: -9662327808.0000 - accuracy: 0.0558 - val_loss: -11946163200.0000 - val_accuracy: 0.0572\n",
      "Epoch 9/20\n",
      "8520/8520 [==============================] - 20s 2ms/step - loss: -13649306624.0000 - accuracy: 0.0557 - val_loss: -16766970880.0000 - val_accuracy: 0.0570\n",
      "Epoch 10/20\n",
      "8520/8520 [==============================] - 21s 2ms/step - loss: -18628997120.0000 - accuracy: 0.0559 - val_loss: -21890242560.0000 - val_accuracy: 0.0572\n",
      "Epoch 11/20\n",
      "8520/8520 [==============================] - 21s 2ms/step - loss: -24664264704.0000 - accuracy: 0.0559 - val_loss: -30745698304.0000 - val_accuracy: 0.0571\n",
      "Epoch 12/20\n",
      "8504/8520 [============================>.] - ETA: 0s - loss: -31874437120.0000 - accuracy: 0.0557"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m y_train \u001b[39m=\u001b[39m features[\u001b[39m0\u001b[39m][:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m y_val \u001b[39m=\u001b[39m features[\u001b[39m1\u001b[39m][:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m model \u001b[39m=\u001b[39m train_model(features[\u001b[39m0\u001b[39;49m], y_train, features[\u001b[39m1\u001b[39;49m], y_val)\n",
      "Cell \u001b[1;32mIn[5], line 46\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m     38\u001b[0m tuner \u001b[39m=\u001b[39m RandomSearch(\n\u001b[0;32m     39\u001b[0m     build_model,\n\u001b[0;32m     40\u001b[0m     objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     project_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmy_model\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     45\u001b[0m )\n\u001b[1;32m---> 46\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val))\n\u001b[0;32m     48\u001b[0m \u001b[39m# Retrieve best hyperparameters and fit the final model\u001b[39;00m\n\u001b[0;32m     49\u001b[0m best_hyperparameters \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_hyperparameters(\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Jamin\\miniconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 230\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\Jamin\\miniconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m    269\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 270\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    271\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jamin\\miniconda3\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 235\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[0;32m    237\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[0;32m    238\u001b[0m     ):\n\u001b[0;32m    239\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    240\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    241\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    243\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    251\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Jamin\\miniconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_and_fit_model(trial, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\Jamin\\miniconda3\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[0;32m    213\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 214\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mfit(hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    216\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m )\n\u001b[0;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\Jamin\\miniconda3\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \n\u001b[0;32m    123\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:1694\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1681\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1682\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1693\u001b[0m     )\n\u001b[1;32m-> 1694\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1695\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1696\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1697\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1698\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1699\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1700\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1701\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1702\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1703\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1704\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1705\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1706\u001b[0m )\n\u001b[0;32m   1707\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1708\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1709\u001b[0m }\n\u001b[0;32m   1710\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py:2040\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2036\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   2037\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   2038\u001b[0m ):\n\u001b[0;32m   2039\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2040\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   2041\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   2042\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    917\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 919\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    920\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    921\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    922\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train model\n",
    "y_train = features[0][:, -1]\n",
    "y_val = features[1][:, -1]\n",
    "model = train_model(features[0], y_train, features[1], y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
